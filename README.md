# ğŸ™ï¸ City Code Finder using Local AI

A **Streamlit-based web app** that helps users find standard Indian **city codes** using:

- ğŸ“š A local city-code database
- ğŸ” Fuzzy matching for close spellings
- ğŸ¤– AI assistance using **Ollama + LLaMA3** for abbreviation and nickname interpretation

This model runs **offline**, and can intelligently resolve even unclear or abbreviated city inputs like `dilli`, `mtt`, or `mum`.

---
## Preview - https://drive.google.com/file/d/1ihvEl3c8RLLe2UZLOTlrrVqROC4NoSWB/view?usp=sharing

## ğŸš€ Features

- âœ… **Search by full city name, short form, or nickname**
- ğŸ§  **Offline LLM support** via Ollama (uses LLaMA3)
- ğŸ” **Fuzzy suggestions** for mistyped city names
- ğŸ“‹ **Reference table** of over 30 Indian cities
- ğŸ”Œ **Works without internet** (AI and database are local)

---

## ğŸ§  What is Ollama?

**[Ollama](https://ollama.ai/)** is a platform to run large language models (LLMs) **locally** on your machine without needing an internet connection. You can run models like **LLaMA 3**, **Gemma**, and others for AI tasks such as text generation and interpretation.

In this project:

- Ollama is used to run **LLaMA3** locally.
- It interprets city nicknames or misspellings (e.g., `dilli` â†’ `delhi`, `mtt` â†’ `meerut`).
- Ensures data privacy and works even when offline.

> ğŸ”§ Ollama is optional â€” the app will still work with basic matching if Ollama is not installed.

---

ğŸ’¡ How It Works
User inputs a city name, code, or abbreviation.

App checks:

âœ… Exact match in city DB

ğŸ”¤ Abbreviation mappings (like mum â†’ mumbai)

ğŸ§  If enabled, AI (Ollama) guesses the city name

ğŸ¤ Fuzzy suggestions using difflib

Returns the official city code (like AU-MUM for Mumbai).




